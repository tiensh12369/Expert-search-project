{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "v0: 통합코드 적용\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB 수집: WOS, 0.3252694606781006\n",
      "check\n",
      "DB 수집: SCOPUS, 0.0023241043090820312\n",
      "2차 통합: 0.3275935649871826\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import itertools\n",
    "import numpy as np\n",
    "import jaro\n",
    "import time\n",
    "#import multicpu\n",
    "\n",
    "client = MongoClient('mongodb://203.255.92.141:27017', authSource='admin')\n",
    "filter_info = client['PUBLIC']['FilterInfo'] #필터접근\n",
    "filters_category = client['PUBLIC']['FilterCategory']\n",
    "\n",
    "f_id = 0 #input\n",
    "keyid = 500 #keyid\n",
    "\n",
    "fid_key_query = filter_info.find_one({ '$and': [{ 'fId': f_id }, { 'keyId': keyid }]}) #f_id serach\n",
    "\n",
    "pinst = []\n",
    "pyear = []\n",
    "pjournal = []\n",
    "plang = []\n",
    "\n",
    "if  fid_key_query != None: #f_id check\n",
    "    for key in fid_key_query.keys() :\n",
    "        if key == 'pFilter' :\n",
    "            pinst = fid_key_query[key]['inst']\n",
    "            pyear = fid_key_query[key]['year']\n",
    "            pjournal = fid_key_query[key]['journal']\n",
    "            plang = fid_key_query[key]['lang']\n",
    "\n",
    "wos_raw = client['WOS']['Rawdata']\n",
    "scopus_raw = client['SCOPUS']['Rawdata']\n",
    "\n",
    "wos_key_query = wos_raw.find({ 'keyId' : keyid })\n",
    "scopus_key_query = scopus_raw.find({ 'keyId' : keyid })\n",
    "\n",
    "key_querys = [wos_key_query, scopus_key_query] #Rawdata\n",
    "id_domestic = client['ID']['Domestic'] #Domestic\n",
    "\n",
    "mng_id = [] # Author id\n",
    "paper = []\n",
    "\n",
    "Answer_dict = {} # Answer result\n",
    "fp_dict = {} #filter papaer result\n",
    "site = ['WOS', 'SCOPUS']\n",
    "\n",
    "savetime1 = 0\n",
    "savetime2 = 0\n",
    "end1 = 0\n",
    "\n",
    "f_pyear = {}\n",
    "f_pinst = {}\n",
    "f_pjournal = {}\n",
    "f_plang = {}\n",
    "\n",
    "Inte_name = []\n",
    "\n",
    "def simple_filter(value, filters) :\n",
    "    if value in filters or filters == []:\n",
    "        return True\n",
    "    return False\n",
    "        \n",
    "def fc_simple_filter(category, fc_dict):\n",
    "    if category not in fc_dict:\n",
    "        fc_dict[category] = 0\n",
    "    fc_dict[category] += 1\n",
    "    return fc_dict\n",
    "\n",
    "for i in range(len(key_querys)):\n",
    "    mng_dict = {}\n",
    "    start1 = time.time()\n",
    "    for key_query in key_querys[i]: #rawdata(magid, paper) insert\n",
    "\n",
    "        if key_query['author_inst'] not in \"\":\n",
    "            paper_year =  key_query['issue_year']\n",
    "            paper_journal = key_query['journal']\n",
    "            # ori_inst = key_query['originalName'].split(';')[-2]\n",
    "            ori_inst = key_query['author_inst'].split(';')[-2]\n",
    "            paper_lang = key_query['issue_lang']\n",
    "            exi_inst = key_query['author_inst'].split(';')[-2]\n",
    "            mng_name = key_query['author'].split(';')[-2]\n",
    "            mng_id = key_query['author_id'].split(';')[-1]\n",
    "            paper = key_query['_id']\n",
    "            \n",
    "        if simple_filter(paper_year, pyear) and simple_filter(paper_journal, pjournal) and simple_filter(ori_inst, pinst) and simple_filter(paper_lang, plang):\n",
    "            if mng_id not in mng_dict:\n",
    "                mng_dict[mng_id] = {'name' : mng_name, 'inst' : exi_inst, 'papers' : [], 'oriInst' : ori_inst}\n",
    "            mng_dict[mng_id]['papers'].append(paper)\n",
    "            fp_dict[paper] = {'year' : paper_year, 'inst' : ori_inst, 'journal' : paper_journal, 'lang' : paper_lang}\n",
    "            \n",
    "    end2 = time.time()\n",
    "    db_time = end2-start1\n",
    "    print(f'DB 수집: {site[i]}, {db_time}')\n",
    "    savetime1 += db_time\n",
    "    \n",
    "    for mng_one in mng_dict :\n",
    "        oriinst = mng_dict[mng_one]['oriInst']\n",
    "        exiinst = mng_dict[mng_one]['inst']\n",
    "        mng_name = mng_dict[mng_one]['name']\n",
    "        paper = mng_dict[mng_one]['papers']\n",
    "\n",
    "        Answer = {'fid': f_id, 'keyId': keyid, 'name' : mng_name , 'inst': oriinst, site[i] : {'inst' :exiinst, 'A_id': [mng_one], 'papers' : paper, 'oriInst' : oriinst} }\n",
    "        \n",
    "        if mng_name not in Answer_dict and mng_name+'_0' not in Answer_dict : #동명이인이 없을 때\n",
    "            Answer_dict[mng_name] = Answer\n",
    "        else :\n",
    "            count = 0\n",
    "            flag = True\n",
    "            while flag :\n",
    "                temp = None\n",
    "                tempName = mng_name\n",
    "                \n",
    "                if tempName in Answer_dict : # 이름 으로만 key가ㅣ 존재         \n",
    "                    temp = Answer_dict[tempName]\n",
    "                    flag = False\n",
    "                else :\n",
    "                    tempName = mng_name+'_'+str(count) # 이름 + 숫자로 key가ㅣ 존재\n",
    "                    if tempName not in Answer_dict :\n",
    "                        flag = False \n",
    "                        break\n",
    "                    temp = Answer_dict[tempName]\n",
    "                        \n",
    "                for key in temp.keys() : # 사이트 돌면서\n",
    "                    if key != 'name' and key != 'keyId' and key != 'fid' and key != 'inst': \n",
    "                        src = \"\"\n",
    "                        tgt = \"\"\n",
    "\n",
    "                        if len(exiinst) >= len(temp[key]['inst']):\n",
    "                            src = temp[key]['inst']\n",
    "                            tgt = exiinst\n",
    "\n",
    "                        elif len(exiinst) < len(temp[key]['inst']):\n",
    "                            src = exiinst\n",
    "                            tgt = temp[key]['inst']\n",
    "\n",
    "                        if key == site[i] :# 사이트가 동일할때\n",
    "                            if temp[key]['inst'] == exiinst or (src != \"\" and src in tgt) :  # 소속 같을때\n",
    "                                Answer_dict[tempName][site[i]]['A_id'].extend([mng_one])\n",
    "                                Answer_dict[tempName][site[i]]['papers'].extend(paper)\n",
    "                                flag = False\n",
    "                                break\n",
    "\n",
    "                            elif mng_name+'_'+str(count+1) not in Answer_dict : #소속이 다를 때\n",
    "                                Answer_dict[mng_name+'_'+str(count+1)] = Answer\n",
    "                                if tempName == mng_name:\n",
    "                                    Answer_dict[mng_name+'_0'] = temp\n",
    "                                    del Answer_dict[mng_name]\n",
    "                                flag = False\n",
    "                                break\n",
    "                            \n",
    "                        else :# 사이트가 다를때 \n",
    "                            if temp[key]['inst'] == exiinst  or (src != \"\" and src in tgt):  # 소속 같을때\n",
    "                                Answer_dict[tempName][site[i]] =  {'inst' : exiinst, 'A_id': [mng_one], 'papers' : paper, 'oriInst' : oriinst}\n",
    "                                Inte_name.append(tempName)\n",
    "                                if '대학교' in Answer_dict[tempName][site[i]]['oriInst'] and '대학교' not in Answer_dict[tempName]['inst']:\n",
    "                                    Answer_dict[tempName]['inst'] = Answer_dict[tempName][site[i]]['oriInst']\n",
    "                                flag = False\n",
    "                                break\n",
    "                            \n",
    "                            elif mng_name+'_'+str(count+1) not in Answer_dict : #소속이 다를 때\n",
    "                                Answer_dict[mng_name+'_'+str(count+1)] = Answer\n",
    "                                if tempName == mng_name:\n",
    "                                    Answer_dict[mng_name+'_0'] = temp\n",
    "                                    del Answer_dict[mng_name]\n",
    "                                flag = False\n",
    "                                break\n",
    "\n",
    "                count += 1\n",
    "end3 = time.time()\n",
    "savetime2 = end3-end2+savetime1\n",
    "\n",
    "print(f'2차 통합: {savetime2}')\n",
    "# print(sorted(Answer_dict.items()))\n",
    "# print(filter_dict)\n",
    "print(Inte_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(rawdata):\n",
    "\n",
    "    coauthor = rawdata['author'].split(\";\")[1:-1]\n",
    "    year = int(rawdata['issue_year'])\n",
    "    paper_keyword = rawdata['paper_keyword']\n",
    "    \n",
    "    if paper_keyword == [] or paper_keyword is None:\n",
    "        keyword = []\n",
    "    elif len(paper_keyword) > 1:\n",
    "        for i in range(0, len(paper_keyword)):\n",
    "            keyword = []\n",
    "            keyword.append(paper_keyword[i].replace(\" \", \"\").split(\".\"))\n",
    "    else:\n",
    "        keyword = paper_keyword.replace(\" \", \"\").split(\".\")\n",
    "\n",
    "    journal = rawdata['journal']\n",
    "    conference = rawdata['issue_inst']\n",
    "    title = rawdata['title']\n",
    "\n",
    "    return coauthor, year, keyword, journal, conference, title\n",
    "\n",
    "def Secondary_filter(name, site1, inst1, raw_one1, site2, inst2, raw_one2):\n",
    "    inst = 0\n",
    "    weight = 0\n",
    "    joc = 0\n",
    "    coauthor1, year1, keyword1, journal1, conference1, title1 = filter(raw_one1)\n",
    "    coauthor2, year2, keyword2, journal2, conference2, title2 = filter(raw_one2)\n",
    "\n",
    "    if inst1 == inst2:\n",
    "        inst = 1\n",
    "    else:\n",
    "        inst = jaro.jaro_winkler_metric(inst1, inst2)\n",
    "\n",
    "    if name in coauthor1:\n",
    "        coauthor1.remove(name)\n",
    "\n",
    "    if name in coauthor2:\n",
    "        coauthor2.remove(name)\n",
    "    \n",
    "    co_author_count = len([i for i in coauthor1 if i in coauthor2])\n",
    "\n",
    "\n",
    "    if title1 == title2 or inst >= 0.8:\n",
    "        weight = 4\n",
    "        return weight\n",
    "\n",
    "    else:\n",
    "        joc = 1 if journal1 == journal2 and conference1 == conference2 else 0\n",
    "\n",
    "            \n",
    "    yop = -(2*(abs(year1-year2)/10)-1)\n",
    "            \n",
    "    if len(coauthor1) == 0 or len(coauthor2) == 0:\n",
    "        co_author_ratio = 0\n",
    "    elif len(coauthor1) < len(coauthor2):\n",
    "        co_author_ratio = co_author_count/len(coauthor1)\n",
    "    else:\n",
    "        co_author_ratio = co_author_count/len(coauthor2)\n",
    "    \n",
    "    if co_author_ratio == 1:\n",
    "        co_authorship = 1\n",
    "    else:\n",
    "        co_authorship = (1 - np.exp(-co_author_count))/2 + (co_author_ratio/2)\n",
    "        \n",
    "    keyword = 1 - np.exp(-len([i for i in keyword1 if i in keyword2]))\n",
    "\n",
    "    # print(f'joc: {joc} | yop: {yop} | co_authorship: {co_authorship} | keyword: {keyword}')\n",
    "    \n",
    "    weight = joc + yop + co_authorship + keyword\n",
    "    print(name, weight)\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pichel, William G. 2.1148475049095032\n",
      "Ramsey, Jon J. 2.432120558828558\n",
      "Gonzalez-Reyes, Jose A. 2.432120558828558\n",
      "Tans, Pieter 0.742376068887963\n",
      "Uliasz-Misiak, Barbara 0.19999999999999996\n",
      "Brantley, Susan L. 1.43151417157617\n",
      "Vinnem, Jan Erik 1.2321205588285578\n",
      "Vinnem, Jan Erik 0.8\n",
      "Bachu, Stefan 1.4321205588285577\n",
      "Naidu, Ravi 2.0321205588285576\n",
      "Naidu, Ravi 0.4\n",
      "Naidu, Ravi 2.0\n",
      "Vengosh, Avner 2.12151273893034\n",
      "Brandt, Adam R. 0.8\n",
      "Brandt, Adam R. 0.8321205588285576\n",
      "Brandt, Adam R. 2.0321205588285576\n",
      "Brandt, Adam R. 0.4\n",
      "Brandt, Adam R. 0.6\n",
      "Brandt, Adam R. 1.4321205588285577\n",
      "Yin, Jianbo 0.6000000000000001\n",
      "Paik, Jeom Kee 0.4\n",
      "Itkin, Maxim 0.8\n",
      "Bernstein, Aaron S. 2.432120558828558\n",
      "Schnell, Russell C. 1.1323323583816935\n",
      "Khan, Faisal 0.8\n",
      "Bedrikovetsky, Pavel 1.8321205588285576\n",
      "Wallmann, Klaus 1.375106465816068\n",
      "Bunger, Andrew P. 1.2321205588285578\n",
      "Dilmore, Robert M. 0.19999999999999996\n",
      "Dilmore, Robert M. 0.1993936127476122\n",
      "Dilmore, Robert M. 0.6\n",
      "Sweeney, Colm 1.6731808382428364\n",
      "Rokunohe, Toshiaki 2.0321205588285576\n",
      "Liang, Yongtu 1.5656656917150271\n",
      "Stanton, Neville A. 1.0827269460809454\n",
      "Hubler, Mija 1.8\n",
      "Pekney, Natalie J. 2.482227024644626\n",
      "Pekney, Natalie J. 2.1981808382428367\n",
      "Murawski, Steven A. 2.197786250543585\n",
      "Shen, Changyu 0.9993936127476122\n",
      "Griffin, Robert J. 2.0321205588285576\n",
      "Lu, J. -0.16787944117144238\n"
     ]
    }
   ],
   "source": [
    "raw_dbs = {'WOS' : wos_raw, 'SCOPUS' : scopus_raw}\n",
    "savetime1 = 0\n",
    "savetime2 = 0\n",
    "def getRaw(name):\n",
    "    if 'raws' not in Answer_dict[name]:\n",
    "        raws = []\n",
    "        for site_one in site:\n",
    "            if site_one in Answer_dict[name]:\n",
    "                for c in raw_dbs[site_one].find({\"_id\": {\"$in\": Answer_dict[name][site_one]['papers']}}):\n",
    "                    c['site'] = site_one\n",
    "                    raws.append(c)\n",
    "        \n",
    "        Answer_dict[name]['raws'] = raws\n",
    "\n",
    "processedList = []\n",
    "deleteList = []\n",
    "\n",
    "for Answer_one in Answer_dict :\n",
    "\n",
    "    if '_' in Answer_one :\n",
    "        start1 = time.time()\n",
    "        name = Answer_one.split(\"_\")\n",
    "        if name[0] in processedList :\n",
    "            continue\n",
    "        preprocessedList = []\n",
    "        c = 0\n",
    "        while True :\n",
    "            pname = name[0]+\"_\"+str(c)\n",
    "            if pname in Answer_dict :            \n",
    "                preprocessedList.append(pname)\n",
    "                getRaw(pname)\n",
    "                c += 1\n",
    "            else :\n",
    "                break\n",
    "        end1 = time.time()\n",
    "        savetime1 += end1 - start1\n",
    "        processedList.append(name[0])\n",
    "        flag = True\n",
    "        while flag :\n",
    "            flag = False\n",
    "            pairs =list(itertools.combinations(preprocessedList, 2))\n",
    "            \n",
    "            for pair in pairs:\n",
    "                pair = list(pair)\n",
    "\n",
    "                raws1 = Answer_dict[pair[0]]['raws']\n",
    "                raws2 = Answer_dict[pair[1]]['raws']\n",
    "                \n",
    "                for ra1, ra2 in zip(raws1, raws2):\n",
    "                    site1 = ra1['site']\n",
    "                    site2 = ra2['site']\n",
    "                    inst1 = Answer_dict[pair[0]][site1]['oriInst']\n",
    "                    inst2 = Answer_dict[pair[1]][site2]['oriInst']\n",
    "\n",
    "                    if Secondary_filter(name[0], site1, inst1, ra1, site2, inst2, ra2) >= 3:\n",
    "                        Inte_name.append(pair[0])\n",
    "                        deleteList.append(pair[1])\n",
    "                        for site_one in site:\n",
    "                            if site_one in Answer_dict[pair[1]]:\n",
    "                                if site_one in Answer_dict[pair[0]].keys() :                            \n",
    "                                    Answer_dict[pair[0]][site_one]['A_id'].extend(Answer_dict[pair[1]][site_one]['A_id'])\n",
    "                                    Answer_dict[pair[0]][site_one]['papers'].extend(Answer_dict[pair[1]][site_one]['papers'])\n",
    "                                    Answer_dict[pair[0]]['raws'].extend(Answer_dict[pair[1]]['raws'])\n",
    "                                    \n",
    "                                    Answer_dict[pair[0]][site_one]['A_id'] = list(set(Answer_dict[pair[0]][site_one]['A_id']))\n",
    "                                    Answer_dict[pair[0]][site_one]['papers'] = list(set(Answer_dict[pair[0]][site_one]['papers']))\n",
    "                                else:\n",
    "                                    Answer_dict[pair[0]][site_one] = Answer_dict[pair[1]][site_one]\n",
    "   \n",
    "                        flag = True\n",
    "                        preprocessedList.remove(pair[1])\n",
    "                        break\n",
    "                if flag :\n",
    "                    break\n",
    "                \n",
    "for d in deleteList:\n",
    "    del Answer_dict[d]\n",
    "\n",
    "for d in Answer_dict : \n",
    "    if 'raws' in Answer_dict[d] :\n",
    "        del Answer_dict[d]['raws']\n",
    "\n",
    "# print(savetime1, savetime2)\n",
    "# print(Answer_dict)\n",
    "# id_domestic.insert_many(Answer_dict.values()) #mongodb 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hossler, Eric': {'fid': 0, 'keyId': 546, 'name': 'Hossler, Eric', 'inst': 'Geisinger Med Ctr, Dept Dermatol, Danville, PA 17822 USA', 'WOS': {'inst': 'Geisinger Med Ctr, Dept Dermatol, Danville, PA 17822 USA', 'A_id': ['s9258150'], 'papers': [ObjectId('6175634c0bd47368d3c83cb0'), ObjectId('6175634c0bd47368d3c83cb0')], 'oriInst': 'Geisinger Med Ctr, Dept Dermatol, Danville, PA 17822 USA'}}, 'Javier Gonzalez, Luis_1': {'fid': 0, 'keyId': 546, 'name': 'Javier Gonzalez, Luis', 'inst': 'Inst Pasteur Montevideo, IIBCE, Montevideo 2020, Uruguay', 'WOS': {'inst': 'Inst Pasteur Montevideo, IIBCE, Montevideo 2020, Uruguay', 'A_id': ['s9258120'], 'papers': [ObjectId('6175632e0bd47368d3c83cac')], 'oriInst': 'Inst Pasteur Montevideo, IIBCE, Montevideo 2020, Uruguay'}}, 'Javier Gonzalez, Luis_0': {'fid': 0, 'keyId': 546, 'name': 'Javier Gonzalez, Luis', 'inst': 'Ctr Genet Engn & Biotechnol, POB 6162, Havana, Cuba', 'WOS': {'inst': 'Ctr Genet Engn & Biotechnol, POB 6162, Havana, Cuba', 'A_id': ['s9258142'], 'papers': [ObjectId('6175632e0bd47368d3c83cae')], 'oriInst': 'Ctr Genet Engn & Biotechnol, POB 6162, Havana, Cuba'}}, 'Steel, Piers': {'fid': 0, 'keyId': 546, 'name': 'Steel, Piers', 'inst': 'Univ Calgary, Haskayne Sch Business, 2500 Univ Dr NW, Calgary, AB, Canada', 'WOS': {'inst': 'Univ Calgary, Haskayne Sch Business, 2500 Univ Dr NW, Calgary, AB, Canada', 'A_id': ['s9258107'], 'papers': [ObjectId('6175632e0bd47368d3c83cab')], 'oriInst': 'Univ Calgary, Haskayne Sch Business, 2500 Univ Dr NW, Calgary, AB, Canada'}}, 'Uggerslev, Krista L.': {'fid': 0, 'keyId': 546, 'name': 'Uggerslev, Krista L.', 'inst': 'Northern Alberta Inst Technol, JR Shaw Sch Business, Edmonton, AB, Canada', 'WOS': {'inst': 'Northern Alberta Inst Technol, JR Shaw Sch Business, Edmonton, AB, Canada', 'A_id': ['s9258124'], 'papers': [ObjectId('6175632e0bd47368d3c83cad')], 'oriInst': 'Northern Alberta Inst Technol, JR Shaw Sch Business, Edmonton, AB, Canada'}}, 'Young, Victor': {'fid': 0, 'keyId': 546, 'name': 'Young, Victor', 'inst': 'Apartado 0843-01466, Panama City, Panama', 'WOS': {'inst': 'Apartado 0843-01466, Panama City, Panama', 'A_id': ['s9258104'], 'papers': [ObjectId('6175632e0bd47368d3c83caa')], 'oriInst': 'Apartado 0843-01466, Panama City, Panama'}}, 'Nimon, Kim': {'fid': 0, 'keyId': 546, 'name': 'Nimon, Kim', 'inst': 'Univ Texas Tyler, Tyler, TX 75799 USA', 'WOS': {'inst': 'Univ Texas Tyler, Tyler, TX 75799 USA', 'A_id': ['s4749059'], 'papers': [ObjectId('6175632e0bd47368d3c83ca9')], 'oriInst': 'Univ Texas Tyler, Tyler, TX 75799 USA'}}, 'Roques, Alain': {'fid': 0, 'keyId': 546, 'name': 'Roques, Alain', 'inst': 'INRA, UR629, Unite Rech Ecol Forets Mediterraneennes, Avignon, France', 'WOS': {'inst': 'INRA, UR629, Unite Rech Ecol Forets Mediterraneennes, Avignon, France', 'A_id': ['s9258101'], 'papers': [ObjectId('6175632e0bd47368d3c83ca8')], 'oriInst': 'INRA, UR629, Unite Rech Ecol Forets Mediterraneennes, Avignon, France'}}, 'Chaves-Campos, Johel': {'fid': 0, 'keyId': 546, 'name': 'Chaves-Campos, Johel', 'inst': 'Council Int Educ Exchange, Trop Ecol & Conservat Study Abrd Program, Monteverde, Costa Rica', 'WOS': {'inst': 'Council Int Educ Exchange, Trop Ecol & Conservat Study Abrd Program, Monteverde, Costa Rica', 'A_id': ['s9258093'], 'papers': [ObjectId('6175632e0bd47368d3c83ca7')], 'oriInst': 'Council Int Educ Exchange, Trop Ecol & Conservat Study Abrd Program, Monteverde, Costa Rica'}}, 'Geiger, Mingang K.': {'fid': 0, 'keyId': 546, 'name': 'Geiger, Mingang K.', 'inst': 'Northern Alberta Inst Technol, Off Res & Innovat, Appl Res Chair Leadership & Talent, Edmonton, AB T5G 2R1, Canada', 'WOS': {'inst': 'Northern Alberta Inst Technol, Off Res & Innovat, Appl Res Chair Leadership & Talent, Edmonton, AB T5G 2R1, Canada', 'A_id': ['s9258091'], 'papers': [ObjectId('6175632e0bd47368d3c83ca6')], 'oriInst': 'Northern Alberta Inst Technol, Off Res & Innovat, Appl Res Chair Leadership & Talent, Edmonton, AB T5G 2R1, Canada'}}, 'Hossler E.': {'fid': 0, 'keyId': 546, 'name': 'Hossler E.', 'inst': 'Department of Dermatology Geisinger Medical Center Danville PA United States', 'SCOPUS': {'inst': 'Department of Dermatology Geisinger Medical Center Danville PA United States', 'A_id': ['6507252692'], 'papers': [ObjectId('617563073fd465dcffc88b6f'), ObjectId('617563073fd465dcffc88b6f')], 'oriInst': 'Department of Dermatology Geisinger Medical Center Danville PA United States'}}, 'Robert V.': {'fid': 0, 'keyId': 546, 'name': 'Robert V.', 'inst': \"Centre National d'Expertise sur les Vecteurs BP 64501 34394 Montpellier Cedex 5 France Institut de Recherche pour le Développement MIVEGEC UMR IRD 224 - CNRS 5290 - UM1 - UM2 BP 64501 34394 Montpellier Cedex 5 France\", 'SCOPUS': {'inst': \"Centre National d'Expertise sur les Vecteurs BP 64501 34394 Montpellier Cedex 5 France Institut de Recherche pour le Développement MIVEGEC UMR IRD 224 - CNRS 5290 - UM1 - UM2 BP 64501 34394 Montpellier Cedex 5 France\", 'A_id': ['8834684300'], 'papers': [ObjectId('617563063fd465dcffc88b6d')], 'oriInst': \"Centre National d'Expertise sur les Vecteurs BP 64501 34394 Montpellier Cedex 5 France Institut de Recherche pour le Développement MIVEGEC UMR IRD 224 - CNRS 5290 - UM1 - UM2 BP 64501 34394 Montpellier Cedex 5 France\"}}, 'Steel P.': {'fid': 0, 'keyId': 546, 'name': 'Steel P.', 'inst': 'Haskayne School of Business University of Calgary Calgary AB Canada', 'SCOPUS': {'inst': 'Haskayne School of Business University of Calgary Calgary AB Canada', 'A_id': ['15137675500'], 'papers': [ObjectId('617563053fd465dcffc88b66'), ObjectId('617563053fd465dcffc88b67')], 'oriInst': 'Haskayne School of Business University of Calgary Calgary AB Canada'}}, 'González L.J.': {'fid': 0, 'keyId': 546, 'name': 'González L.J.', 'inst': 'Center for Genetic Engineering and Biotechnology PO Box 6162 Havana Cuba', 'SCOPUS': {'inst': 'Center for Genetic Engineering and Biotechnology PO Box 6162 Havana Cuba', 'A_id': ['7202218576'], 'papers': [ObjectId('617563043fd465dcffc88b65'), ObjectId('617563053fd465dcffc88b68')], 'oriInst': 'Center for Genetic Engineering and Biotechnology PO Box 6162 Havana Cuba'}}, 'Uggerslev K.L.': {'fid': 0, 'keyId': 546, 'name': 'Uggerslev K.L.', 'inst': 'JR Shaw School of Business Northern Alberta Institute of Technology Edmonton Canada', 'SCOPUS': {'inst': 'JR Shaw School of Business Northern Alberta Institute of Technology Edmonton Canada', 'A_id': ['8925211000'], 'papers': [ObjectId('617563063fd465dcffc88b69')], 'oriInst': 'JR Shaw School of Business Northern Alberta Institute of Technology Edmonton Canada'}}, 'Roques A.': {'fid': 0, 'keyId': 546, 'name': 'Roques A.', 'inst': 'INRA UR633 Zoologie Forestière Orléans 45075 France', 'SCOPUS': {'inst': 'INRA UR633 Zoologie Forestière Orléans 45075 France', 'A_id': ['55443683500'], 'papers': [ObjectId('617563063fd465dcffc88b6b')], 'oriInst': 'INRA UR633 Zoologie Forestière Orléans 45075 France'}}, 'Torzi I.': {'fid': 0, 'keyId': 546, 'name': 'Torzi I.', 'inst': 'Università degli Studi di Bergamo Liceo Scientifico Vittorio Veneto Milano Italy', 'SCOPUS': {'inst': 'Università degli Studi di Bergamo Liceo Scientifico Vittorio Veneto Milano Italy', 'A_id': ['57214259960'], 'papers': [ObjectId('617563063fd465dcffc88b6c')], 'oriInst': 'Università degli Studi di Bergamo Liceo Scientifico Vittorio Veneto Milano Italy'}}, 'Chaves-Campos J.': {'fid': 0, 'keyId': 546, 'name': 'Chaves-Campos J.', 'inst': 'Council on International Educational Exchange Tropical Ecology and Conservation Study Abroad Program Monteverde Costa Rica', 'SCOPUS': {'inst': 'Council on International Educational Exchange Tropical Ecology and Conservation Study Abroad Program Monteverde Costa Rica', 'A_id': ['10143033700'], 'papers': [ObjectId('6175630c3fd465dcffc88b71')], 'oriInst': 'Council on International Educational Exchange Tropical Ecology and Conservation Study Abroad Program Monteverde Costa Rica'}}, 'Geiger M.K.': {'fid': 0, 'keyId': 546, 'name': 'Geiger M.K.', 'inst': 'Department of Management John Chambers College of Business and Economics West Virginia University Morgantown WV  26506 United States', 'SCOPUS': {'inst': 'Department of Management John Chambers College of Business and Economics West Virginia University Morgantown WV  26506 United States', 'A_id': ['57205272555'], 'papers': [ObjectId('617563073fd465dcffc88b70')], 'oriInst': 'Department of Management John Chambers College of Business and Economics West Virginia University Morgantown WV  26506 United States'}}, 'Garciá-Zambrano B.': {'fid': 0, 'keyId': 546, 'name': 'Garciá-Zambrano B.', 'inst': 'Dirección General de Salud Ambiental-Ministerio del Poder Popular para la Salud (DGSA-MPPS) Maracay Venezuela', 'SCOPUS': {'inst': 'Dirección General de Salud Ambiental-Ministerio del Poder Popular para la Salud (DGSA-MPPS) Maracay Venezuela', 'A_id': ['57223231732'], 'papers': [ObjectId('617563063fd465dcffc88b6a')], 'oriInst': 'Dirección General de Salud Ambiental-Ministerio del Poder Popular para la Salud (DGSA-MPPS) Maracay Venezuela'}}}\n"
     ]
    }
   ],
   "source": [
    "for check_name in set(Inte_name): #통합저자\n",
    "    paper_check = {} #paper_id : title : co_author\n",
    "    del_paper = [] #del paper list\n",
    "    if check_name in Answer_dict.keys():\n",
    "        for site_one in site:\n",
    "            if site_one in Answer_dict[check_name]:\n",
    "                for raw_one in raw_dbs[site_one].find({\"_id\": {\"$in\": Answer_dict[check_name][site_one]['papers']}}):\n",
    "                    if raw_one['title'] not in paper_check.keys(): #중복 title이 아니면\n",
    "                        \n",
    "                        for key_check in paper_check: #paper_chck에 있는 title과 유사도 비교\n",
    "                            paper_sim = jaro.jaro_winkler_metric(key_check, raw_one['title'])\n",
    "                            \n",
    "                            if paper_sim >= 0.8: #유사도가 80% 이상이면\n",
    "                                if paper_check[key_check]['co_author'] == raw_one['author'].split(';')[:-1]: #공동저자 비교\n",
    "                                    if raw_one['_id'] in Answer_dict[check_name][site_one]['papers']:\n",
    "                                        del_paper.append({raw_one['_id'] : raw_one['title']})\n",
    "                                        # print(f'del_1: {del_paper}')\n",
    "                                        Answer_dict[check_name][site_one]['papers'].remove(raw_one['_id'])\n",
    "                                        del fp_dict[raw_one['_id']]\n",
    "                                        break\n",
    "\n",
    "                        paper_check[raw_one['title']] = {'paper_id' : raw_one['_id'], 'co_author' : raw_one['author'].split(';')[:-1]}\n",
    "                        \n",
    "                    else: #중복 title이면\n",
    "                        del_paper.append({raw_one['_id'] : raw_one['title']})\n",
    "                        # print(f'del_2: {del_paper}')\n",
    "                        Answer_dict[check_name][site_one]['papers'].remove(raw_one['_id'])\n",
    "                        del fp_dict[raw_one['_id']]\n",
    "                if Answer_dict[check_name][site_one]['papers'] == []: #site에 papers가 비어있으면 site 삭제\n",
    "                    del Answer_dict[check_name][site_one]\n",
    "                        \n",
    "print(Answer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fp in fp_dict:\n",
    "    f_pyear = fc_simple_filter(fp_dict[fp]['year'], f_pyear)\n",
    "    f_pinst = fc_simple_filter(fp_dict[fp]['inst'].replace(\".\", \"^\"), f_pinst)\n",
    "    f_pjournal = fc_simple_filter(fp_dict[fp]['journal'].replace(\".\", \"^\"), f_pjournal)\n",
    "    f_plang = fc_simple_filter(fp_dict[fp]['lang'], f_plang)\n",
    "    \n",
    "filter_dict= {'keyId': keyid, 'fId': f_id, 'paper': { \n",
    "                'year': {'list': f_pyear, 'k': 'year', 'v': '연도' },\n",
    "                'inst': {'k': 'inst', 'list': f_pinst, 'v': '소속', 'f': 'false' },\n",
    "                'journal': {'list': f_pjournal, 'k': 'journal', 'v': '저널'},\n",
    "                'lang': {'list': f_plang, 'k': 'lang', 'v': '언어' }\n",
    "            },\n",
    "            'project': {\n",
    "                'year': {'list': f_nyear, 'k': 'year', 'v': '연도' },\n",
    "                'inst': {'list': f_ninst, 'k': 'inst', 'v': '소속' },\n",
    "                'fund': {'k': 'fund', 'v': '과제수주비', 'list': f_nfund },\n",
    "                'rsc': {'k': 'rsc', 'v': '참여인원', 'list': f_nrsc }\n",
    "            }}\n",
    "\n",
    "filters_category.insert_one(filter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = multicpu.run_factor_integration(keyid, f_id)\n",
    "analyzer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9426c78cac494a5ae5a22e0d5f8fa48da7e4c0f608effbd156736920c37fea9b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('mlearn': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
