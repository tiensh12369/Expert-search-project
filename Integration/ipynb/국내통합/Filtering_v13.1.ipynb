{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "v1: Scienceon, DBPIA, NTIS AuthorPapers 접근하여 Rawdata에서 필터링된 papers를 추가\n",
    "v2: Answer 변경 및 f_id 수정 중\n",
    "v3: time, tqdm 추가하여 속도 확인\n",
    "v4: Scienceon, DBPIA에 mng로 검색 추가\n",
    "v5: DBPIA 삭제하고 KCI 추가 & Rawdata 먼저 접급으로 변경, answer check 추가\n",
    "v5.1: 대학테이블, 정답비교 코드 추가\n",
    "v6: nFilter, pFilter 조건 비교 함수 추가(ntis_filter, paper_filter)\n",
    "v6.1: 대학테이블, 정답비교 코드 추가, sites => site, Answer['inst'] 추가\n",
    "v7: Autor 접근 삭제, Rawdata에서 소속 이름 가져오기 추가, inst값 없는 문제 해결, A_id 나눠들어가는 문제 해결\n",
    "v8: multicpu 코드 불러오기, 웹 필터 카테고리, paper_journal을 (. -> ^)로 변환\n",
    "v9: KeyError NAME 이 뜨는 오류 해결(flag=False, break), auts 삭제\n",
    "v10: dbpia 추가\n",
    "v11: 중복 논문 제거(논문 유사도, 저자 비교)\n",
    "v11.1: 중복 논문 제거(공백제거)\n",
    "v12: 중복 논문 제거한 필터\n",
    "v13: 해외통합 연결 및 필터카테고리 중복 키 에러 해결\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB 수집: SCIENCEON, 0.13402843475341797\n",
      "DB 수집: NTIS, 0.04198598861694336\n",
      "DB 수집: KCI, 0.01680898666381836\n",
      "DB 수집: DBPIA, 0.022533893585205078\n",
      "2차 통합: 0.21635746955871582\n",
      "795\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import itertools\n",
    "import numpy as np\n",
    "import jaro\n",
    "import time\n",
    "# import sys\n",
    "# import os\n",
    "# import multicpu_220504\n",
    "\n",
    "client = MongoClient('mongodb://203.255.92.141:27017', authSource='admin')\n",
    "filter_info = client['PUBLIC']['FilterInfo'] #필터접근\n",
    "filters_category = client['PUBLIC']['FilterCategory']\n",
    "\n",
    "f_id = 0 #input\n",
    "keyid = 984 #keyid\n",
    "\n",
    "fid_key_query = filter_info.find_one({ '$and': [{ 'fId': f_id }, { 'keyId': keyid }]}) #f_id serach\n",
    "ninst = []\n",
    "nrsc = []\n",
    "nfund = []\n",
    "nyear = []\n",
    "pinst = []\n",
    "pyear = []\n",
    "pjournal = []\n",
    "plang = []\n",
    "\n",
    "if  fid_key_query != None: #f_id check\n",
    "    for key in fid_key_query.keys() :\n",
    "        if key == 'nFilter':\n",
    "            ninst = fid_key_query[key]['inst'] #소속\n",
    "            nrsc = fid_key_query[key]['rsc'] #공동저자수\n",
    "            nfund = fid_key_query[key]['fund'] #과제수주비\n",
    "            nyear = fid_key_query[key]['year'] #연도\n",
    "\n",
    "        elif key == 'pFilter' :\n",
    "            pinst = fid_key_query[key]['inst']\n",
    "            pyear = fid_key_query[key]['year']\n",
    "            pjournal = fid_key_query[key]['journal']\n",
    "            plang = fid_key_query[key]['lang']\n",
    "\n",
    "dbpia_aut = client['DBPIA']['Author']\n",
    "\n",
    "scion_raw = client['SCIENCEON']['Rawdata']\n",
    "ntis_raw = client['NTIS']['Rawdata']\n",
    "kci_raw = client['KCI']['Rawdata']\n",
    "dbpia_raw = client['DBPIA']['Rawdata']\n",
    "\n",
    "scion_key_query = scion_raw.find({ 'keyId' : keyid })\n",
    "ntis_key_query = ntis_raw.find({ 'keyId' : keyid })\n",
    "kci_key_query = kci_raw.find({ 'keyId' : keyid })\n",
    "dbpia_key_query = dbpia_raw.find({ 'keyId' : keyid })\n",
    "\n",
    "key_querys = [scion_key_query, ntis_key_query, kci_key_query, dbpia_key_query] #Rawdata\n",
    "id_domestic = client['ID']['Domestic'] #Domestic\n",
    "\n",
    "mng_id = [] # Author id\n",
    "paper = []\n",
    "\n",
    "Answer_dict = {} # Answer result\n",
    "fp_dict = {} #filter papaer result\n",
    "site = ['SCIENCEON', 'NTIS', 'KCI', 'DBPIA']\n",
    "fund = [0, 50000000, 100000000, 300000000, 500000000, 1000000000, 10000000000000 ]\n",
    "rsc = [0, 10, 30, 50, 100, 100000]\n",
    "\n",
    "dbpia_mng_ids = {}\n",
    "dbpia_paper_year = []\n",
    "dbpia_paper_journal = []\n",
    "dbpia_ori_inst = []\n",
    "dbpia_paper_lang = []\n",
    "dbpia_exi_inst = []\n",
    "dbpia_mng_name = []\n",
    "dbpia_paper = []\n",
    "\n",
    "savetime1 = 0\n",
    "savetime2 = 0\n",
    "end1 = 0\n",
    "\n",
    "f_nyear = {}\n",
    "f_ninst = {}\n",
    "f_nfund = {'0':0, '1':0, '2':0, '3':0, '4':0, '5':0}\n",
    "f_nrsc = {'0':0, '1':0, '2':0, '3':0, '4':0}\n",
    "f_pyear = {}\n",
    "f_pinst = {}\n",
    "f_pjournal = {}\n",
    "f_plang = {}\n",
    "\n",
    "Inte_name = []\n",
    "\n",
    "def simple_filter(value, filters) :\n",
    "    if value in filters or filters == []:\n",
    "        return True\n",
    "    return False\n",
    "        \n",
    "def complex_filter(value, filters, base) :\n",
    "    if filters == []:\n",
    "        return True\n",
    "\n",
    "    for j in range(len(filters)):\n",
    "        if base[filters[j]] <= float(value) < base[filters[j]+1]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def fc_simple_filter(category, fc_dict):\n",
    "    if category not in fc_dict:\n",
    "        fc_dict[category] = 0\n",
    "    fc_dict[category] += 1\n",
    "    return fc_dict\n",
    "\n",
    "def fc_complex_filter(category, base, fc_dict):\n",
    "    for j in range(len(base)-1):\n",
    "        if base[j] <= float(category) < base[j+1]:\n",
    "            fc_dict[str(j)] += 1\n",
    "            return fc_dict\n",
    "\n",
    "for i in range(len(key_querys)):\n",
    "    mng_dict = {}\n",
    "    start1 = time.time()\n",
    "    for key_query in key_querys[i]: #rawdata(magid, paper) insert\n",
    "        if site[i] == 'NTIS' :\n",
    "            ori_inst = key_query['originalName']\n",
    "            ntis_rsc = int(key_query['cntRscMan']) + int(key_query['cntRscWom'])\n",
    "            ntis_fund = key_query['totalFund']\n",
    "            ntis_year = str(key_query['prdStart'][:4])\n",
    "            exi_inst = key_query['ldAgency']\n",
    "            mng_name =  key_query['mng']\n",
    "            mng_id = key_query['mngId']\n",
    "            paper = key_query['_id']\n",
    "\n",
    "            if simple_filter(ori_inst, ninst) and simple_filter(ntis_year, nyear) and complex_filter(ntis_fund, nfund, fund) and complex_filter(ntis_rsc, nrsc, rsc):\n",
    "                if mng_id not in mng_dict:\n",
    "                    mng_dict[mng_id] = {'name' : mng_name, 'inst' : exi_inst, 'papers' : [], 'oriInst' : ori_inst}\n",
    "                mng_dict[mng_id]['papers'].append(paper)\n",
    "                f_nyear = fc_simple_filter(ntis_year, f_nyear)\n",
    "                f_ninst = fc_simple_filter(ori_inst, f_ninst)\n",
    "                f_nfund = fc_complex_filter(ntis_fund, fund, f_nfund)\n",
    "                f_nrsc = fc_complex_filter(ntis_rsc, rsc, f_nrsc)\n",
    "                \n",
    "        elif site[i] == 'DBPIA':\n",
    "            mng_id = key_query['mngId']\n",
    "            if mng_id not in dbpia_mng_ids:\n",
    "                dbpia_paper_year = str(key_query['issue_year'][:4])\n",
    "                dbpia_paper_journal = key_query['journal']\n",
    "                dbpia_paper_lang = key_query['issue_lang']\n",
    "                dbpia_mng_name = key_query['author'].split(';')[-2]\n",
    "                dbpia_paper = key_query['_id']\n",
    "                dbpia_mng_ids[mng_id] = {'year': dbpia_paper_year, 'journal': dbpia_paper_journal, 'lang': dbpia_paper_lang, 'name': dbpia_mng_name, 'paper' : dbpia_paper}\n",
    "                \n",
    "        else:\n",
    "            if key_query['author_inst'] not in \"\":\n",
    "                paper_year =  str(key_query['issue_year'][:4])\n",
    "                paper_journal = key_query['journal']\n",
    "                ori_inst = key_query['originalName'].split(';')[-2]\n",
    "                paper_lang = key_query['issue_lang']\n",
    "                exi_inst = key_query['author_inst'].split(';')[-2]\n",
    "                mng_name = key_query['author'].split(';')[-2]\n",
    "                mng_id = key_query['mngId']\n",
    "                paper = key_query['_id']\n",
    "\n",
    "            if simple_filter(paper_year, pyear) and simple_filter(paper_journal, pjournal) and simple_filter(ori_inst, pinst) and simple_filter(paper_lang, plang):\n",
    "                if mng_id not in mng_dict:\n",
    "                    mng_dict[mng_id] = {'name' : mng_name, 'inst' : exi_inst, 'papers' : [], 'oriInst' : ori_inst}\n",
    "                mng_dict[mng_id]['papers'].append(paper)\n",
    "                fp_dict[paper] = {'year' : paper_year, 'inst' : ori_inst, 'journal' : paper_journal, 'lang' : paper_lang}\n",
    "                \n",
    "    if site[i] == 'DBPIA':\n",
    "        dbpia_aut_query = dbpia_aut.find({ '_id' : {'$in' : list(dbpia_mng_ids.keys())}})\n",
    "        for aut_query_one in dbpia_aut_query:\n",
    "            hasInst = aut_query_one['hasInst']\n",
    "            if hasInst == False:\n",
    "                continue\n",
    "            paper_year =  str(dbpia_mng_ids[aut_query_one['_id']]['year'])\n",
    "            paper_journal = dbpia_mng_ids[aut_query_one['_id']]['journal']\n",
    "            exi_inst = aut_query_one['inst']\n",
    "            ori_inst = aut_query_one['originalName']\n",
    "            paper_lang = dbpia_mng_ids[aut_query_one['_id']]['lang']\n",
    "            mng_name = dbpia_mng_ids[aut_query_one['_id']]['name']\n",
    "            mng_id = aut_query_one['_id']\n",
    "            paper = dbpia_mng_ids[aut_query_one['_id']]['paper']\n",
    "            \n",
    "            if simple_filter(paper_year, pyear) and simple_filter(paper_journal, pjournal) and simple_filter(ori_inst, pinst) and simple_filter(paper_lang, plang):\n",
    "                if mng_id not in mng_dict:\n",
    "                    mng_dict[mng_id] = {'name' : mng_name, 'inst' : exi_inst, 'papers' : [], 'oriInst' : ori_inst}\n",
    "                mng_dict[mng_id]['papers'].append(paper)\n",
    "                fp_dict[paper] = {'year' : paper_year, 'inst' : ori_inst, 'journal' : paper_journal, 'lang' : paper_lang}\n",
    "                \n",
    "    end2 = time.time()\n",
    "    db_time = end2-start1\n",
    "    print(f'DB 수집: {site[i]}, {db_time}')\n",
    "    savetime1 += db_time\n",
    "    \n",
    "    for mng_one in mng_dict:\n",
    "        oriinst = mng_dict[mng_one]['oriInst']\n",
    "        exiinst = mng_dict[mng_one]['inst']\n",
    "        mng_name = mng_dict[mng_one]['name']\n",
    "        paper = mng_dict[mng_one]['papers']\n",
    "\n",
    "        Answer = {'fid': f_id, 'keyId': keyid, 'name' : mng_name , 'inst': oriinst, site[i] : {'inst' :exiinst, 'A_id': [mng_one], 'papers' : paper, 'oriInst' : oriinst} }\n",
    "        \n",
    "        if mng_name not in Answer_dict and mng_name+'_0' not in Answer_dict : #동명이인이 없을 때\n",
    "            Answer_dict[mng_name] = Answer\n",
    "        else :\n",
    "            count = 0\n",
    "            flag = True\n",
    "            while flag :\n",
    "                temp = None\n",
    "                tempName = mng_name\n",
    "                \n",
    "                if tempName in Answer_dict : # 이름 으로만 key가ㅣ 존재         \n",
    "                    temp = Answer_dict[tempName]\n",
    "                    flag = False\n",
    "                else :\n",
    "                    tempName = mng_name+'_'+str(count) # 이름 + 숫자로 key가ㅣ 존재\n",
    "                    if tempName not in Answer_dict :\n",
    "                        flag = False \n",
    "                        break\n",
    "                    temp = Answer_dict[tempName]\n",
    "                        \n",
    "                for key in temp.keys() : # 사이트 돌면서\n",
    "                    if key != 'name' and key != 'keyId' and key != 'fid' and key != 'inst': \n",
    "                        src = \"\"\n",
    "                        tgt = \"\"\n",
    "\n",
    "                        if len(exiinst) >= len(temp[key]['inst']):\n",
    "                            src = temp[key]['inst']\n",
    "                            tgt = exiinst\n",
    "\n",
    "                        elif len(exiinst) < len(temp[key]['inst']):\n",
    "                            src = exiinst\n",
    "                            tgt = temp[key]['inst']\n",
    "\n",
    "                        if key == site[i] :# 사이트가 동일할때\n",
    "                            if temp[key]['inst'] == exiinst or (src != \"\" and src in tgt): # 소속 같을때\n",
    "                                Answer_dict[tempName][site[i]]['A_id'].extend([mng_one]) #저자 id 합치기\n",
    "                                Answer_dict[tempName][site[i]]['papers'].extend(paper) #논문 id 합치기\n",
    "                                flag = False\n",
    "                                break\n",
    "\n",
    "                            elif mng_name+'_'+str(count+1) not in Answer_dict : #소속이 다를 때\n",
    "                                Answer_dict[mng_name+'_'+str(count+1)] = Answer\n",
    "                                if tempName == mng_name:\n",
    "                                    Answer_dict[mng_name+'_0'] = temp\n",
    "                                    del Answer_dict[mng_name]\n",
    "                                flag = False\n",
    "                                break\n",
    "                            \n",
    "                        else :# 사이트가 다를때 \n",
    "                            if temp[key]['inst'] == exiinst  or (src != \"\" and src in tgt):  # 소속 같을때\n",
    "                                Answer_dict[tempName][site[i]] =  {'inst' : exiinst, 'A_id': [mng_one], 'papers' : paper, 'oriInst' : oriinst}\n",
    "                                Inte_name.append(tempName)\n",
    "                                if '대학교' in Answer_dict[tempName][site[i]]['oriInst'] and '대학교' not in Answer_dict[tempName]['inst']:\n",
    "                                    Answer_dict[tempName]['inst'] = Answer_dict[tempName][site[i]]['oriInst']\n",
    "                                flag = False\n",
    "                                break\n",
    "                            \n",
    "                            elif mng_name+'_'+str(count+1) not in Answer_dict : #소속이 다를 때\n",
    "                                Answer_dict[mng_name+'_'+str(count+1)] = Answer\n",
    "                                if tempName == mng_name:\n",
    "                                    Answer_dict[mng_name+'_0'] = temp\n",
    "                                    del Answer_dict[mng_name]\n",
    "                                flag = False\n",
    "                                break\n",
    "\n",
    "                count += 1\n",
    "end3 = time.time()\n",
    "savetime2 = end3-end2+savetime1\n",
    "\n",
    "print(f'2차 통합: {savetime2}')\n",
    "print(len(Answer_dict))\n",
    "# print(sorted(Answer_dict.items()))\n",
    "# print(filter_dict)\n",
    "# print(Inte_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(site, rawdata):\n",
    "    if site == 'NTIS' :\n",
    "        coauthor = rawdata['rsc'].split(\";\")\n",
    "        year = int(rawdata['prdStart'][:4])\n",
    "        keyword = rawdata['koKeyword'].split(\",\")\n",
    "        journal = \"\"\n",
    "        conference = \"\"\n",
    "        title = \"\"\n",
    "\n",
    "    else :\n",
    "        coauthor = rawdata['author'].split(\";\")[:-1]\n",
    "        year = int(rawdata['issue_year'][:4])\n",
    "        paper_keyword = rawdata['paper_keyword']\n",
    "        \n",
    "        if paper_keyword == [] or paper_keyword is None:\n",
    "            keyword = []\n",
    "            print(1, keyword)\n",
    "        elif type(paper_keyword) is list:\n",
    "            for i in range(0, len(paper_keyword)):\n",
    "                keyword = []\n",
    "                keyword.append(paper_keyword[i].replace(\" \", \"\").split(\".\"))\n",
    "            print(2, keyword)\n",
    "        else:\n",
    "            keyword = paper_keyword.replace(\" \", \"\").split(\".\")\n",
    "            if keyword[0] == '':\n",
    "                keyword = []\n",
    "            print(3, keyword)\n",
    "        \n",
    "        journal = rawdata['journal']\n",
    "        conference = rawdata['issue_inst']\n",
    "        title = rawdata['title']\n",
    "        \n",
    "    return coauthor, year, keyword, journal, conference, title\n",
    "\n",
    "def Secondary_filter(name, site1, inst1, raw_one1, site2, inst2, raw_one2):\n",
    "    inst = 0\n",
    "    weight = 0\n",
    "    joc = 0\n",
    "    coauthor1, year1, keyword1, journal1, conference1, title1 = filter(site1, raw_one1)\n",
    "    coauthor2, year2, keyword2, journal2, conference2, title2 = filter(site2, raw_one2)\n",
    "\n",
    "    if inst1 == inst2:\n",
    "        inst = 1\n",
    "    else:\n",
    "        inst = jaro.jaro_winkler_metric(inst1, inst2)\n",
    "\n",
    "    if name in coauthor1:\n",
    "        coauthor1.remove(name)\n",
    "\n",
    "    if name in coauthor2:\n",
    "        coauthor2.remove(name)\n",
    "    \n",
    "    co_author_count = len([i for i in coauthor1 if i in coauthor2])\n",
    "\n",
    "    if site1 != 'NTIS' and site2 != 'NTIS' :\n",
    "        if title1 == title2 or inst >= 0.8:\n",
    "            weight = 4\n",
    "            return weight\n",
    "\n",
    "        else:\n",
    "            joc = 1 if journal1 == journal2 and conference1 == conference2 else 0\n",
    "    else:\n",
    "        if inst >= 0.8:\n",
    "            weight = 4\n",
    "            return weight\n",
    "            \n",
    "    yop = -(2*(abs(year1-year2)/10)-1)\n",
    "            \n",
    "    if len(coauthor1) == 0 or len(coauthor2) == 0:\n",
    "        co_author_ratio = 0\n",
    "    elif len(coauthor1) < len(coauthor2):\n",
    "        co_author_ratio = co_author_count/len(coauthor1)\n",
    "    else:\n",
    "        co_author_ratio = co_author_count/len(coauthor2)\n",
    "    \n",
    "    if co_author_ratio == 1:\n",
    "        co_authorship = 1\n",
    "    else:\n",
    "        co_authorship = (1 - np.exp(-co_author_count))/2 + (co_author_ratio/2)\n",
    "    keyword = 1 - np.exp(-len([i for i in keyword1 if i in keyword2]))\n",
    "\n",
    "    print(f'joc: {joc} | yop: {yop} | co_authorship: {co_authorship} | keyword: {keyword}')\n",
    "    print(f'name1: {name} | site1: {site1} | year: {year1} | coauthor: {coauthor1} | keyword: {keyword1} | journal1: {journal1}')\n",
    "    print(f'name2: {name} | site1: {site2} | year: {year2} | coauthor: {coauthor2} | keyword: {keyword2} | journal2: {journal2}')\n",
    "    \n",
    "    weight = joc + yop + co_authorship + keyword\n",
    "\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 []\n",
      "1 []\n",
      "joc: 0 | yop: 1.0 | co_authorship: 0.4160602794142788 | keyword: 0.0\n",
      "name1: Xiong, Rong | site1: SCIENCEON | year: 2021 | coauthor: ['Pan, Yiyuan', 'Xu, Xuecheng', 'Ding, Xiaqing', 'Huang, Shoudong', 'Wang, Yue'] | keyword: [] | journal1: IEEE transactions on instrumentation and measurement\n",
      "name2: Xiong, Rong | site1: SCIENCEON | year: 2021 | coauthor: ['Chen, Runjian', 'Yin, Huan', 'Jiao, Yanmei', 'Dissanayake, Gamini', 'Wang, Yue'] | keyword: [] | journal2: IEEE robotics and automation letters\n",
      "1 []\n",
      "3 ['Localization', 'Sensorfusion', 'Visual-inertialSLAM', 'LIDARSLAM', 'UAV', 'Unmannedsystems']\n",
      "joc: 0 | yop: 1.0 | co_authorship: 0.5660602794142788 | keyword: 0.0\n",
      "name1: Xie, Lihua | site1: SCIENCEON | year: 2021 | coauthor: ['Wang, Han', 'Wang, Chen'] | keyword: [] | journal1: IEEE robotics and automation letters\n",
      "name2: Xie, Lihua | site1: SCIENCEON | year: 2021 | coauthor: ['Yuan, Shenghai', 'Wang, Han'] | keyword: ['Localization', 'Sensorfusion', 'Visual-inertialSLAM', 'LIDARSLAM', 'UAV', 'Unmannedsystems'] | journal2: Unmanned systems\n",
      "1 []\n",
      "1 []\n",
      "joc: 0 | yop: 1.0 | co_authorship: 0.4160602794142788 | keyword: 0.0\n",
      "name1: Asama, Hajime | site1: SCIENCEON | year: 2021 | coauthor: ['Bao, Runqiu', 'Komatsu, Ren', 'Miyagusuku, Renato', 'Chino, Masaki', 'Yamashita, Atsushi'] | keyword: [] | journal1: Advanced robotics : the international journal of the Robotics Society of Japan\n",
      "name2: Asama, Hajime | site1: SCIENCEON | year: 2021 | coauthor: ['Wang, Yusheng', 'Ji, Yonghoon', 'Woo, Hanwool', 'Tamura, Yusuke', 'Tsuchiya, Hiroshi', 'Yamashita, Atsushi'] | keyword: [] | journal2: IEEE journal of oceanic engineering\n",
      "1 []\n",
      "1 []\n",
      "joc: 0 | yop: 1.0 | co_authorship: 0.8908421805556329 | keyword: 0.0\n",
      "name1: Umeda, Kazunori | site1: SCIENCEON | year: 2021 | coauthor: ['Kataoka, Ryosuke', 'Suzuki, Ryuki', 'Ji, Yonghoon', 'Fujii, Hiromitsu', 'Kono, Hitoshi'] | keyword: [] | journal1: System Integration (SII), 2021 IEEE/SICE International Symposium on\n",
      "name2: Umeda, Kazunori | site1: SCIENCEON | year: 2021 | coauthor: ['Kataoka, Ryosuke', 'Tadokoro, Isao', 'Ji, Yonghoon', 'Fujii, Hiromitsu', 'Kono, Hitoshi'] | keyword: [] | journal2: Ubiquitous Robots (UR), 2021 18th International Conference on\n",
      "1 []\n",
      "1 []\n",
      "joc: 0 | yop: 1.0 | co_authorship: 0.775106465816068 | keyword: 0.0\n",
      "name1: Debei, Stefano | site1: SCIENCEON | year: 2021 | coauthor: ['Chiodini, Sebastiano', 'Giubilato, Riccardo', 'Pertile, Marco', 'Salvioli, Federico', 'Bussi, Diego', 'Barrera, Marco', 'Franceschetti, Paola'] | keyword: [] | journal1: IEEE transactions on instrumentation and measurement\n",
      "name2: Debei, Stefano | site1: SCIENCEON | year: 2021 | coauthor: ['Chiodini, Sebastiano', 'Giubilato, Riccardo', 'Pertile, Marco', 'Tedesco, Annarita', 'Accardo, Domenico'] | keyword: [] | journal2: Metrology for AeroSpace (MetroAeroSpace), 2021 IEEE 8th International Workshop on\n",
      "1 []\n",
      "1 []\n",
      "joc: 0 | yop: 0.8 | co_authorship: 0.48272694608094546 | keyword: 0.0\n",
      "name1: Liu, Yunhui | site1: SCIENCEON | year: 2022 | coauthor: ['Chen, Wenqiang', 'Wang, Yu', 'Chen, Haoyao'] | keyword: [] | journal1: Journal of field robotics\n",
      "name2: Liu, Yunhui | site1: SCIENCEON | year: 2021 | coauthor: ['Li, Yuxiang', 'Su, Pengpeng', 'Cao, Ming', 'Chen, Haoyao', 'Jiang, Xin'] | keyword: [] | journal2: Real-time Computing and Robotics (RCAR), 2021 IEEE International Conference on\n",
      "1 []\n",
      "1 []\n",
      "joc: 0 | yop: 1.0 | co_authorship: 0.0 | keyword: 0.0\n",
      "name1: Park, Soon-Yong | site1: SCIENCEON | year: 2021 | coauthor: ['Lee, Junesuk'] | keyword: [] | journal1: IEEE robotics and automation letters\n",
      "name2: Park, Soon-Yong | site1: SCIENCEON | year: 2021 | coauthor: ['Lee, Ung-Gyo', 'Choi, Kyung-Jea'] | keyword: [] | journal2: Ubiquitous and Future Networks (ICUFN), 2021 Twelfth International Conference on\n",
      "1 []\n",
      "1 []\n",
      "joc: 0 | yop: 1.0 | co_authorship: 0.850106465816068 | keyword: 0.0\n",
      "name1: Stricker, Didier | site1: SCIENCEON | year: 2021 | coauthor: ['Shu, Fangwen', 'Lesur, Paul', 'Xie, Yaxu', 'Pagani, Alain'] | keyword: [] | journal1: Applications of Computer Vision (WACV), 2021 IEEE Winter Conference on\n",
      "name2: Stricker, Didier | site1: SCIENCEON | year: 2021 | coauthor: ['Shu, Fangwen', 'Xie, Yaxu', 'Rambach, Jason', 'Pagani, Alain'] | keyword: [] | journal2: Mixed and Augmented Reality Adjunct (ISMAR-Adjunct), 2021 IEEE International Symposium on\n",
      "1 []\n",
      "1 []\n",
      "joc: 0 | yop: 1.0 | co_authorship: 1 | keyword: 0.0\n",
      "name1: Hu, Zhanyi | site1: SCIENCEON | year: 2021 | coauthor: ['Liu, Jinxu', 'Gao, Wei'] | keyword: [] | journal1: IEEE robotics and automation letters\n",
      "name2: Hu, Zhanyi | site1: SCIENCEON | year: 2021 | coauthor: ['Liu, Jinxu', 'Gao, Wei'] | keyword: [] | journal2: Robotics and Automation (ICRA), 2021 IEEE International Conference on\n",
      "1 []\n",
      "1 []\n",
      "joc: 0 | yop: 1.0 | co_authorship: 1 | keyword: 0.0\n",
      "name1: Banno, Atsuhiko | site1: SCIENCEON | year: 2021 | coauthor: ['Koide, Kenji', 'Miura, Jun', 'Yokozuka, Masashi', 'Oishi, Shuji'] | keyword: [] | journal1: IEEE robotics and automation letters\n",
      "name2: Banno, Atsuhiko | site1: SCIENCEON | year: 2021 | coauthor: ['Yokozuka, Masashi', 'Koide, Kenji', 'Oishi, Shuji'] | keyword: [] | journal2: Robotics and Automation (ICRA), 2021 IEEE International Conference on\n",
      "1 []\n",
      "1 []\n",
      "joc: 1 | yop: 1.0 | co_authorship: 0.0 | keyword: 0.0\n",
      "name1: Leonard, John J. | site1: SCIENCEON | year: 2021 | coauthor: ['Huang, Qiangqiang', 'Pu, Can', 'Fourie, Dehann', 'Khosoussi, Kasra', 'How, Jonathan P.'] | keyword: [] | journal1: Robotics and Automation (ICRA), 2021 IEEE International Conference on\n",
      "name2: Leonard, John J. | site1: SCIENCEON | year: 2021 | coauthor: ['Zhang, Yihao'] | keyword: [] | journal2: Robotics and Automation (ICRA), 2021 IEEE International Conference on\n",
      "1 []\n",
      "1 []\n",
      "joc: 1 | yop: 1.0 | co_authorship: 0.765665691715027 | keyword: 0.0\n",
      "name1: Leonard, John J. | site1: SCIENCEON | year: 2021 | coauthor: ['Fu, Jiahui', 'Huang, Qiangqiang', 'Doherty, Kevin', 'Wang, Yue'] | keyword: [] | journal1: Intelligent Robots and Systems (IROS), 2021 IEEE/RSJ International Conference on\n",
      "name2: Leonard, John J. | site1: SCIENCEON | year: 2021 | coauthor: ['Lu, Ziqi', 'Huang, Qiangqiang', 'Doherty, Kevin'] | keyword: [] | journal2: Intelligent Robots and Systems (IROS), 2021 IEEE/RSJ International Conference on\n",
      "1 []\n",
      "1 []\n",
      "joc: 0 | yop: 1.0 | co_authorship: 0.775106465816068 | keyword: 0.0\n",
      "name1: Liu, Ming | site1: SCIENCEON | year: 2021 | coauthor: ['Jiao, Jianhao', 'Huang, Huaiyang', 'Li, Liang', 'He, Zhijian', 'Zhu, Yilong'] | keyword: [] | journal1: Computer Vision and Pattern Recognition Workshops (CVPRW), 2021 IEEE/CVF Conference on\n",
      "name2: Liu, Ming | site1: SCIENCEON | year: 2021 | coauthor: ['Jiao, Jianhao', 'Zhu, Yilong', 'Ye, Haoyang', 'Huang, Huaiyang', 'Yun, Peng', 'Jiang, Linxin', 'Wang, Lujia'] | keyword: [] | journal2: Robotics and Automation (ICRA), 2021 IEEE International Conference on\n",
      "1 []\n",
      "1 []\n",
      "joc: 0 | yop: 1.0 | co_authorship: 0.0 | keyword: 0.0\n",
      "name1: Wang, Yao | site1: SCIENCEON | year: 2021 | coauthor: ['Chen, Yanjiang', 'Wang, Yanbo', 'Lin, Junqin', 'Chen, Zhihong'] | keyword: [] | journal1: Consumer Electronics and Computer Engineering (ICCECE), 2021 IEEE International Conference on\n",
      "name2: Wang, Yao | site1: SCIENCEON | year: 2021 | coauthor: ['Wei, Guodong', 'Yang, Hongwei', 'Shi, Weili', 'Jiang, Zhengang', 'Chen, Tao'] | keyword: [] | journal2: Electronic Information Engineering and Computer Science (EIECS), 2021 International Conference on\n",
      "1 []\n",
      "1 []\n",
      "joc: 0 | yop: 1.0 | co_authorship: 0.4160602794142788 | keyword: 0.0\n",
      "name1: Ren, Pengju | site1: SCIENCEON | year: 2021 | coauthor: ['Xiong, Fan', 'Ding, Yan', 'Yu, Mingrui', 'Zhao, Wenzhe', 'Zheng, Nanning'] | keyword: [] | journal1: Neural Networks (IJCNN), 2021 International Joint Conference on\n",
      "name2: Ren, Pengju | site1: SCIENCEON | year: 2021 | coauthor: ['Wang, Cheng', 'Liu, Yingkun', 'Zuo, Kedai', 'Tong, Jianming', 'Ding, Yan'] | keyword: [] | journal2: Field-Programmable Technology (ICFPT), 2021 International Conference on\n",
      "1 []\n",
      "1 []\n",
      "joc: 0 | yop: 1.0 | co_authorship: 0.0 | keyword: 0.0\n",
      "name1: Zhang, Hong | site1: SCIENCEON | year: 2021 | coauthor: ['Lin, Xubin', 'Yang, Yirui', 'He, Li', 'Chen, Weinan', 'Guan, Yisheng'] | keyword: [] | journal1: Robotics and Automation (ICRA), 2021 IEEE International Conference on\n",
      "name2: Zhang, Hong | site1: SCIENCEON | year: 2021 | coauthor: ['Loo, Shing Yan', 'Mashohor, Syamsiah', 'Tang, Sai Hong'] | keyword: [] | journal2: Intelligent Robots and Systems (IROS), 2021 IEEE/RSJ International Conference on\n",
      "3 ['Simultaneouslocalizationandmapping(SLAM)', 'Groundrobot', 'Encoder', 'Sensorfusion', 'Tightcouplingscheme']\n",
      "1 []\n",
      "joc: 0 | yop: 1.0 | co_authorship: 1 | keyword: 0.0\n",
      "name1: Wang, Zhidong | site1: SCIENCEON | year: 2021 | coauthor: ['Su, Yun', 'Wang, Ting', 'Shao, Shiliang', 'Yao, Chen'] | keyword: ['Simultaneouslocalizationandmapping(SLAM)', 'Groundrobot', 'Encoder', 'Sensorfusion', 'Tightcouplingscheme'] | journal1: Robotics and autonomous systems\n",
      "name2: Wang, Zhidong | site1: SCIENCEON | year: 2021 | coauthor: ['Wang, Ting', 'Su, Yun', 'Shao, Shiliang', 'Yao, Chen'] | keyword: [] | journal2: Intelligent Robots and Systems (IROS), 2021 IEEE/RSJ International Conference on\n",
      "joc: 0 | yop: 0.8 | co_authorship: 0.0 | keyword: 0.0\n",
      "name1: 이재호 | site1: NTIS | year: 2021 | coauthor: ['None'] | keyword: ['SLAM', 'Deep learning', 'UAM', '3D map including airspace'] | journal1: \n",
      "name2: 이재호 | site1: NTIS | year: 2022 | coauthor: ['강지헌'] | keyword: ['실내측위', '기계학습', '6G 슬램', '위치인식'] | journal2: \n",
      "3 []\n",
      "1 []\n",
      "joc: 0 | yop: 1.0 | co_authorship: 1 | keyword: 0.0\n",
      "name1: 최준열 | site1: KCI | year: 2021 | coauthor: ['김윤성', '이돈근', '정성훈', '문형일', '유창승', '이강영'] | keyword: [] | journal1: 제어.로봇.시스템학회 논문지\n",
      "name2: 최준열 | site1: DBPIA | year: 2021 | coauthor: ['김윤성', '이돈근', '정성훈', '문형일', '유창승', '이강영'] | keyword: [] | journal2: 제어로봇시스템학회 논문지\n",
      "1 []\n",
      "1 []\n",
      "joc: 0 | yop: 1.0 | co_authorship: 0.0 | keyword: 0.0\n",
      "name1: 이동훈 | site1: DBPIA | year: 2021 | coauthor: ['김태호', '김동진', '민동규', '서현지', '윤호진', '정은빈', '이진강', '권혁재', '김진석', '김대국', '문일주', '유정흠', '최현성'] | keyword: [] | journal1: 대한기계학회 춘추학술대회\n",
      "name2: 이동훈 | site1: DBPIA | year: 2021 | coauthor: ['권욱현', '허소정', '김영애'] | keyword: [] | journal2: 한국심리학회지: 상담 및 심리치료\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "raw_dbs = {'NTIS' : ntis_raw, 'SCIENCEON' : scion_raw, 'KCI' : kci_raw, 'DBPIA': dbpia_raw}\n",
    "savetime1 = 0\n",
    "savetime2 = 0\n",
    "def getRaw(name):\n",
    "    if 'raws' not in Answer_dict[name]:\n",
    "        raws = []\n",
    "        for site_one in site:\n",
    "            if site_one in Answer_dict[name]:\n",
    "                for c in raw_dbs[site_one].find({\"_id\": {\"$in\": Answer_dict[name][site_one]['papers']}}):\n",
    "                    c['site'] = site_one\n",
    "                    raws.append(c)\n",
    "        \n",
    "        Answer_dict[name]['raws'] = raws\n",
    "\n",
    "processedList = []\n",
    "deleteList = []\n",
    "\n",
    "for Answer_one in Answer_dict :\n",
    "\n",
    "    if '_' in Answer_one :\n",
    "        start1 = time.time()\n",
    "        name = Answer_one.split(\"_\")\n",
    "        if name[0] in processedList :\n",
    "            continue\n",
    "        preprocessedList = []\n",
    "        c = 0\n",
    "        while True :\n",
    "            pname = name[0]+\"_\"+str(c)\n",
    "            if pname in Answer_dict :            \n",
    "                preprocessedList.append(pname)\n",
    "                getRaw(pname)\n",
    "                c += 1\n",
    "            else :\n",
    "                break\n",
    "        end1 = time.time()\n",
    "        savetime1 += end1 - start1\n",
    "        processedList.append(name[0])\n",
    "        flag = True\n",
    "        while flag :\n",
    "            flag = False\n",
    "            pairs =list(itertools.combinations(preprocessedList, 2))\n",
    "            \n",
    "            for pair in pairs:\n",
    "                pair = list(pair)\n",
    "\n",
    "                raws1 = Answer_dict[pair[0]]['raws']\n",
    "                raws2 = Answer_dict[pair[1]]['raws']\n",
    "                \n",
    "                for ra1, ra2 in zip(raws1, raws2):\n",
    "                    site1 = ra1['site']\n",
    "                    site2 = ra2['site']\n",
    "                    inst1 = Answer_dict[pair[0]][site1]['oriInst']\n",
    "                    inst2 = Answer_dict[pair[1]][site2]['oriInst']\n",
    "                    \n",
    "                    # for site_one in site:\n",
    "                    #     if site_one in Answer_dict[pair[0]] and site_one in Answer_dict[pair[1]] :\n",
    "                    #         print(site_one, Answer_dict[pair[0]][site_one]['A_id'], Answer_dict[pair[1]][site_one]['A_id'])\n",
    "                                        \n",
    "                    if Secondary_filter(name[0], site1, inst1, ra1, site2, inst2, ra2) >= 3:\n",
    "                        Inte_name.append(pair[0])\n",
    "                        deleteList.append(pair[1])\n",
    "                        for site_one in site:\n",
    "                            if site_one in Answer_dict[pair[1]]:\n",
    "                                if site_one in Answer_dict[pair[0]].keys() :                            \n",
    "                                    Answer_dict[pair[0]][site_one]['A_id'].extend(Answer_dict[pair[1]][site_one]['A_id'])\n",
    "                                    Answer_dict[pair[0]][site_one]['papers'].extend(Answer_dict[pair[1]][site_one]['papers'])\n",
    "                                    Answer_dict[pair[0]]['raws'].extend(Answer_dict[pair[1]]['raws'])\n",
    "                                    \n",
    "                                    Answer_dict[pair[0]][site_one]['A_id'] = list(set(Answer_dict[pair[0]][site_one]['A_id']))\n",
    "                                    Answer_dict[pair[0]][site_one]['papers'] = list(set(Answer_dict[pair[0]][site_one]['papers']))\n",
    "                                else:\n",
    "                                    Answer_dict[pair[0]][site_one] = Answer_dict[pair[1]][site_one]\n",
    "   \n",
    "                        flag = True\n",
    "                        preprocessedList.remove(pair[1])\n",
    "                        break\n",
    "                if flag :\n",
    "                    break\n",
    "                \n",
    "for d in deleteList:\n",
    "    del Answer_dict[d]\n",
    "\n",
    "for d in Answer_dict : \n",
    "    if 'raws' in Answer_dict[d] :\n",
    "        del Answer_dict[d]['raws']\n",
    "print(len(Inte_name))\n",
    "# print(savetime1, savetime2)\n",
    "# id_domestic.insert_many(Answer_dict.values()) #mongodb 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'answer984.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d3f8a27e7949>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'answer{keyid}.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8-sig'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0ma_json\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'answer984.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "answer = None\n",
    "numCor = 0\n",
    "numErr = 0\n",
    "numInteErr = 0\n",
    "answerCounter = {}\n",
    "\n",
    "def ansCheck(result, name) :\n",
    "    global answer, numCor, numErr, answerCounter, numInteErr\n",
    "    flag = True\n",
    "\n",
    "    numK = len(result.keys())    \n",
    "    if numK-4 != len(answer[name].keys()) :\n",
    "        flag = False\n",
    "    else :\n",
    "        for site in result.keys() :        \n",
    "            if site != 'name' and site != 'fid' and site != 'keyId' and site != 'inst':\n",
    "                if site not in answer[name].keys() :\n",
    "                    flag = False\n",
    "                else: \n",
    "                    if numK > 5:\n",
    "                        if answer[name][site] != result[site]['inst'] :\n",
    "                            flag = False\n",
    "                    else :\n",
    "                        if answer[name][site] != result[site]['inst'] and  answer[name][site] != result[site]['inst'].split(' ')[0]:\n",
    "                            flag = False\n",
    "    if flag :\n",
    "        numCor += 1\n",
    "        answerCounter[name] += 1\n",
    "    else :\n",
    "       \n",
    "        if len(answer[name].keys()) > 1 :\n",
    "            numInteErr += 1\n",
    "            print(f\"IIIIIIIIIIIIIIIIIIIIIIIIIIII Not Correct \\n - Answer : {answer[name]}\\n - Result : {result}\")\n",
    "        else :\n",
    "            pass\n",
    "        numErr += 1\n",
    "    return flag\n",
    "\n",
    "with open(f'answer{keyid}.json', 'r',encoding='utf-8-sig') as a_json :\n",
    "\n",
    "    answer = json.load(a_json)\n",
    "    numAns = print(len(answer))\n",
    "    for key in answer.keys() :\n",
    "        answerCounter[key] = 0\n",
    "\n",
    "    for answer_one in Answer_dict:\n",
    "        test = answer_one\n",
    "        \n",
    "        name = Answer_dict[test]['name'].split('_')[0]\n",
    "        \n",
    "        if name in answer :\n",
    "            ansCheck(Answer_dict[test], name)\n",
    "\n",
    "        else :\n",
    "            count = 0\n",
    "            while name+str(count) in answer :\n",
    "                if ansCheck(Answer_dict[test], name+str(count)) :\n",
    "                    break\n",
    "                count += 1\n",
    "\n",
    "    print(f\"num코렉트 {numCor}\")\n",
    "    print(f\"numEror {numErr}\")\n",
    "    print(f\"numInteEror {numInteErr}\")\n",
    "    totalError = 0\n",
    "    totalInteError1 = 0\n",
    "    totalInteError2 = 0\n",
    "    answercount = 0\n",
    "    totalInte = 0\n",
    "\n",
    "    for key in answerCounter.keys() :\n",
    "        answercount += 1\n",
    "        if answerCounter[key] == 0 :\n",
    "            totalError += 1\n",
    "            print(\"answer=\",key, answer[key])\n",
    "            if len(answer[key].keys()) > 1 :\n",
    "                totalInteError1 += 1\n",
    "\n",
    "        else:\n",
    "            if len(answer[key].keys()) > 1 :\n",
    "                totalInteError2 += 1\n",
    "\n",
    "    print(\"토탈앤써\", answercount) \n",
    "    print(\"토탈인터그레이션\", totalInteError1 + totalInteError2)\n",
    "    print(\"--------------------------------\")\n",
    "    print(\"토탈에러\", totalError) \n",
    "    print(\"토탈인터그레이션에러\", totalInteError1)\n",
    "    print(keyid)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9426c78cac494a5ae5a22e0d5f8fa48da7e4c0f608effbd156736920c37fea9b"
  },
  "kernelspec": {
   "display_name": "craw",
   "language": "python",
   "name": "craw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
